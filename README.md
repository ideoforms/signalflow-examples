# SignalFlow Examples

These examples are designed to take you through different approaches to sound design and audio signal processing using Python and the [SignalFlow](https://github.com/ideoforms/signalflow) library.

## Examples

- [Computer keyboard](computer-keyboard): Using the computer keyboard as a real-time control device
- [Computer vision](computer-vision): Using a webcam to do real-time hand tracking and body tracking, for gesture-based control of musical parameters
- [Head tracker](head-tracker): Using the [Supperware head tracker](https://supperware.co.uk/headtracker-overview) for real-time low-latency spatial control
- [MIDI](midi): Responding to MIDI CC values from an attached controller
- [Raspberry Pi](raspberry-pi): Examples of sensor-based controls for the [Raspberry Pi](https://www.raspberrypi.com/) single-board computer, including IMU and time-of-flight sensors (requires additional hardware)

## Tutorials

- [I. Percussion Synthesis](notebooks/Python%20Percussion%20Workshop.ipynb): For the Kilele Instruments Builders workshop

## Code of Conduct

All IRL SignalFlow workshops follow the [Berlin Code of Conduct](https://berlincodeofconduct.org/). We want all attendees to have an enjoyable and fulfilling experience. 

If you are experiencing harassment or have concerns, please contact **Daniel Jones** ([@ideoforms](https://www.instagram.com/ideoforms)).

